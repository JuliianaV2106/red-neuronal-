{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5fd6d99",
   "metadata": {},
   "source": [
    "# Informe: Implementación de una Red Neuronal desde Cero y Comparación con Keras/TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4943cb",
   "metadata": {},
   "source": [
    "* Angela Maria Gonzalez Cordoba\n",
    "* Juan Manuel Casanova Marin\n",
    "* Juliana Filigrana Valencia "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896b90f3",
   "metadata": {},
   "source": [
    "El aprendizaje profundo permite construir modelos capaces de aprender patrones complejos a partir de datos. En este trabajo se implementa una red neuronal desde cero, sin usar librerías de alto nivel, con el objetivo de comprender el funcionamiento interno del entrenamiento mediante propagación hacia adelante, propagación hacia atrás y descenso de gradiente.\n",
    "\n",
    "Posteriormente, se entrena un modelo equivalente utilizando una librería profesional (Keras/TensorFlow) y se comparan los resultados obtenidos. Para este experimento se utiliza un dataset distinto al visto en clase, tomado de Kaggle, concretamente el dataset Titanic, cuyo objetivo es predecir la supervivencia de los pasajeros."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856ae14a",
   "metadata": {},
   "source": [
    "### Dataset: Titanic (Kaggle):\n",
    "\n",
    "El dataset Titanic contiene información de pasajeros del Titanic y la variable objetivo indica si el pasajero sobrevivió (1) o no (0).\n",
    "\n",
    "- Variables utilizadas:\n",
    "\n",
    "- Pclass: clase del boleto\n",
    "\n",
    "- Sex: sexo del pasajero\n",
    "\n",
    "- Age: edad\n",
    "\n",
    "- SibSp: hermanos/esposos a bordo\n",
    "\n",
    "- Parch: padres/hijos a bordo\n",
    "\n",
    "- Fare: tarifa pagada\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68132428",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12791940",
   "metadata": {},
   "source": [
    "### Cargar y preparar el dataset Titanic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73473145",
   "metadata": {},
   "source": [
    "\n",
    "El preprocesamiento de los datos incluyó la selección de variables relevantes, el tratamiento de valores faltantes, la codificación de variables categóricas y la normalización de los datos.\n",
    "\n",
    "Antes de entrenar la red neuronal, se realizaron los siguientes pasos de preprocesamiento:\n",
    "\n",
    "- Se cargó el dataset Titanic desde un archivo CSV.\n",
    "\n",
    "- Se seleccionaron únicamente las variables relevantes para la predicción de la supervivencia.\n",
    "\n",
    "- La variable categórica Sex fue codificada en formato numérico.\n",
    "\n",
    "- Los valores faltantes de la variable Age fueron reemplazados por la media.\n",
    "\n",
    "- Se separaron las variables independientes (X) y la variable objetivo (y).\n",
    "\n",
    "- El conjunto de datos se dividió en entrenamiento (80%) y prueba (20%).\n",
    "\n",
    "- Las características fueron normalizadas utilizando StandardScaler para mejorar la convergencia del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ebff609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (6, 712)\n",
      "y_train: (1, 712)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Angela\\AppData\\Local\\Temp\\ipykernel_6664\\2450025653.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[\"Age\"].fillna(df[\"Age\"].mean(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Cargar dataset\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "\n",
    "# Seleccionar columnas útiles\n",
    "df = df[[\"Survived\", \"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\"]]\n",
    "\n",
    "# Convertir variable categórica\n",
    "df[\"Sex\"] = df[\"Sex\"].map({\"male\": 0, \"female\": 1})\n",
    "\n",
    "# Rellenar valores faltantes\n",
    "df[\"Age\"].fillna(df[\"Age\"].mean(), inplace=True)\n",
    "\n",
    "# Separar X e y\n",
    "X = df.drop(\"Survived\", axis=1).values\n",
    "y = df[\"Survived\"].values.reshape(1, -1)\n",
    "\n",
    "# Train / Test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y.T, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "X_train = X_train.T\n",
    "X_test = X_test.T\n",
    "y_train = y_train.T\n",
    "y_test = y_test.T\n",
    "\n",
    "# Normalizar\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train.T).T\n",
    "X_test = scaler.transform(X_test.T).T\n",
    "\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"y_train:\", y_train.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6d70a1",
   "metadata": {},
   "source": [
    "- El conjunto de entrenamiento contiene 712 muestras.\n",
    "\n",
    "- Cada muestra está descrita por 6 variables de entrada.\n",
    "\n",
    "- La variable objetivo tiene dimensión (1, 712), correspondiente a una etiqueta binaria por muestra.\n",
    "\n",
    "- Los datos fueron organizados en el formato requerido por la implementación manual de la red neuronal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c960a9f3",
   "metadata": {},
   "source": [
    "### Red neuronal **Manual**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd3d47a",
   "metadata": {},
   "source": [
    "**Función sigmoide:**\n",
    "\n",
    "- Utilizada en la capa de salida.\n",
    "\n",
    "- Convierte los valores en probabilidades entre 0 y 1.\n",
    "\n",
    "- Es adecuada para problemas de clasificación binaria.\n",
    "\n",
    "**Función ReLU (Rectified Linear Unit):**\n",
    "\n",
    "- Utilizada en la capa oculta.\n",
    "\n",
    "- Ayuda a evitar el problema del gradiente desvanecido.\n",
    "\n",
    "- Permite un entrenamiento más eficiente en redes profundas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5d35a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def relu(z):\n",
    "    return np.maximum(0, z)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e32d13",
   "metadata": {},
   "source": [
    "**Inicialización de los parámetros de la red**\n",
    "\n",
    "Para comenzar el entrenamiento de la red neuronal, se inicializaron los pesos y sesgos de cada capa de la siguiente manera:\n",
    "\n",
    "- Los pesos fueron inicializados con valores aleatorios pequeños para evitar saturación temprana de las funciones de activación.\n",
    "\n",
    "- Los sesgos (bias) fueron inicializados en cero.\n",
    "\n",
    "- Se utilizó una semilla aleatoria para garantizar la reproducibilidad de los resultados.\n",
    "\n",
    "La red cuenta con:\n",
    "\n",
    "1. Una capa de entrada con n_x características.\n",
    "\n",
    "2. Una capa oculta con n_h neuronas.\n",
    "\n",
    "3. Una capa de salida con una sola neurona para la clasificación binaria.\n",
    "\n",
    "Esta inicialización permite un inicio estable del proceso de entrenamiento mediante descenso por gradiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d19920a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(n_x, n_h):\n",
    "    np.random.seed(1)\n",
    "    W1 = np.random.randn(n_h, n_x) * 0.01\n",
    "    b1 = np.zeros((n_h, 1))\n",
    "    W2 = np.random.randn(1, n_h) * 0.01\n",
    "    b2 = np.zeros((1, 1))\n",
    "    return W1, b1, W2, b2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ee5956",
   "metadata": {},
   "source": [
    " **Propagación hacia adelante (Forward Propagation)**\n",
    " \n",
    "En esta etapa se calcula la salida de la red neuronal a partir de los datos de entrada:\n",
    "\n",
    "- Se realiza una combinación lineal entre las entradas y los pesos de la capa oculta.\n",
    "\n",
    "- Se aplica la función de activación ReLU para obtener las activaciones de la capa oculta.\n",
    "\n",
    "- Se calcula la combinación lineal de la capa de salida.\n",
    "\n",
    "- Se aplica la función sigmoide para obtener la probabilidad de supervivencia.\n",
    "\n",
    "- Se almacenan los valores intermedios necesarios para la fase de retropropagación.\n",
    "\n",
    "Este proceso permite que la red genere una predicción a partir de las características de entrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "247b5e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, W1, b1, W2, b2):\n",
    "    Z1 = np.dot(W1, X) + b1\n",
    "    A1 = relu(Z1)\n",
    "    Z2 = np.dot(W2, A1) + b2\n",
    "    A2 = sigmoid(Z2)\n",
    "    cache = (Z1, A1, Z2, A2)\n",
    "    return A2, cache\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6eacabc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(A2, Y):\n",
    "    m = Y.shape[1]\n",
    "    cost = -(1/m) * np.sum(\n",
    "        Y * np.log(A2 + 1e-8) + (1 - Y) * np.log(1 - A2 + 1e-8)\n",
    "    )\n",
    "    return cost\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b67d42",
   "metadata": {},
   "source": [
    "**Retropropagación del error (Backpropagation)**\n",
    "\n",
    "En esta fase se calculan los gradientes necesarios para actualizar los parámetros de la red neuronal:\n",
    "\n",
    "- Se calcula el error en la capa de salida comparando la predicción con el valor real.\n",
    "\n",
    "- Se obtienen los gradientes de los pesos y sesgos de la capa de salida.\n",
    "\n",
    "- El error se propaga hacia atrás hasta la capa oculta.\n",
    "\n",
    "- Se utiliza la derivada de la función ReLU para calcular el gradiente en la capa oculta.\n",
    "\n",
    "- Se calculan los gradientes correspondientes a los pesos y sesgos de la capa oculta.\n",
    "\n",
    "- Los gradientes se normalizan dividiendo por el número de muestras de entrenamiento.\n",
    "\n",
    "Este procedimiento permite ajustar los parámetros de la red mediante descenso por gradiente, minimizando la función de costo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5a51af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagation(X, Y, cache, W2):\n",
    "    m = X.shape[1]\n",
    "    Z1, A1, Z2, A2 = cache\n",
    "\n",
    "    dZ2 = A2 - Y\n",
    "    dW2 = (1/m) * np.dot(dZ2, A1.T)\n",
    "    db2 = (1/m) * np.sum(dZ2, axis=1, keepdims=True)\n",
    "\n",
    "    dA1 = np.dot(W2.T, dZ2)\n",
    "    dZ1 = dA1 * (Z1 > 0)\n",
    "    dW1 = (1/m) * np.dot(dZ1, X.T)\n",
    "    db1 = (1/m) * np.sum(dZ1, axis=1, keepdims=True)\n",
    "\n",
    "    return dW1, db1, dW2, db2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1437a142",
   "metadata": {},
   "source": [
    "**Entrenamiento de la red neuronal (Training)**\n",
    "Se obtiene el número de características de entrada n_x y se inicializan los parámetros (W1, b1, W2, b2).\n",
    "\n",
    "Durante cada iteración:\n",
    "\n",
    "- Se realiza la propagación hacia adelante para obtener las predicciones A2.\n",
    "\n",
    "- Se calcula el costo usando la función de pérdida (entropía cruzada binaria).\n",
    "\n",
    "- Se ejecuta la retropropagación para calcular los gradientes de los parámetros.\n",
    "\n",
    "- Se actualizan los parámetros mediante descenso por gradiente usando el learning_rate.\n",
    "\n",
    "- Cada 500 iteraciones se imprime el costo para observar si el modelo está aprendiendo correctamente.\n",
    "\n",
    "Este proceso se repite num_iterations veces hasta que el costo disminuya y el modelo logre una mejor capacidad de predicción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7c67664",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn(X, Y, n_h, learning_rate, num_iterations):\n",
    "    n_x = X.shape[0]\n",
    "    W1, b1, W2, b2 = initialize_parameters(n_x, n_h)\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "        A2, cache = forward_propagation(X, W1, b1, W2, b2)\n",
    "        cost = compute_cost(A2, Y)\n",
    "        dW1, db1, dW2, db2 = backward_propagation(X, Y, cache, W2)\n",
    "\n",
    "        W1 -= learning_rate * dW1\n",
    "        b1 -= learning_rate * db1\n",
    "        W2 -= learning_rate * dW2\n",
    "        b2 -= learning_rate * db2\n",
    "\n",
    "        if i % 500 == 0:\n",
    "            print(f\"Iteración {i} - Costo: {cost:.4f}\")\n",
    "\n",
    "    return W1, b1, W2, b2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ae7af7",
   "metadata": {},
   "source": [
    "**Predicción del modelo**\n",
    "Una vez entrenada la red neuronal, se utiliza el modelo para generar predicciones sobre nuevos datos:\n",
    "\n",
    "- Se realiza una propagación hacia adelante con los parámetros entrenados.\n",
    "\n",
    "- La salida del modelo corresponde a una probabilidad entre 0 y 1.\n",
    "\n",
    "- Se aplica un umbral de 0.5 para convertir la probabilidad en una clase binaria.\n",
    "\n",
    "El resultado final indica si el pasajero sobrevive (1) o no sobrevive (0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b1f6c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, W1, b1, W2, b2):\n",
    "    A2, _ = forward_propagation(X, W1, b1, W2, b2)\n",
    "    return (A2 > 0.5).astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57122b0d",
   "metadata": {},
   "source": [
    "**Experimentación con distintos hiperparámetros**\n",
    "\n",
    "Con el objetivo de analizar el impacto de los hiperparámetros en el desempeño del modelo, se entrenaron varias configuraciones de la red neuronal:\n",
    "\n",
    "- Se evaluaran diferentes cantidades de neuronas en la capa oculta (n_h).\n",
    "\n",
    "- Se probara distintos valores de la tasa de aprendizaje (learning_rate).\n",
    "\n",
    "Para cada configuración:\n",
    "\n",
    "- Se entrenó la red durante 3000 iteraciones.\n",
    "\n",
    "- Se generaron predicciones sobre los conjuntos de entrenamiento y prueba.\n",
    "\n",
    "- Se calculó el accuracy en ambos conjuntos.\n",
    "\n",
    "Esta comparación permitió observar cómo la complejidad del modelo y la tasa de aprendizaje afectan la capacidad de generalización.\n",
    "\n",
    "Este análisis facilita la selección de una arquitectura adecuada y evita problemas como el subajuste o el sobreajuste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44829b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "Configuración: {'n_h': 4, 'lr': 0.01}\n",
      "==============================\n",
      "Iteración 0 - Costo: 0.6931\n",
      "Iteración 500 - Costo: 0.6648\n",
      "Iteración 1000 - Costo: 0.6612\n",
      "Iteración 1500 - Costo: 0.6550\n",
      "Iteración 2000 - Costo: 0.6302\n",
      "Iteración 2500 - Costo: 0.5791\n",
      "Accuracy train: 0.778\n",
      "Accuracy test : 0.799\n",
      "\n",
      "==============================\n",
      "Configuración: {'n_h': 8, 'lr': 0.01}\n",
      "==============================\n",
      "Iteración 0 - Costo: 0.6931\n",
      "Iteración 500 - Costo: 0.6644\n",
      "Iteración 1000 - Costo: 0.6576\n",
      "Iteración 1500 - Costo: 0.6238\n",
      "Iteración 2000 - Costo: 0.5235\n",
      "Iteración 2500 - Costo: 0.4642\n",
      "Accuracy train: 0.809\n",
      "Accuracy test : 0.793\n",
      "\n",
      "==============================\n",
      "Configuración: {'n_h': 16, 'lr': 0.005}\n",
      "==============================\n",
      "Iteración 0 - Costo: 0.6931\n",
      "Iteración 500 - Costo: 0.6710\n",
      "Iteración 1000 - Costo: 0.6639\n",
      "Iteración 1500 - Costo: 0.6601\n",
      "Iteración 2000 - Costo: 0.6537\n",
      "Iteración 2500 - Costo: 0.6376\n",
      "Accuracy train: 0.681\n",
      "Accuracy test : 0.654\n"
     ]
    }
   ],
   "source": [
    "configs = [\n",
    "    {\"n_h\": 4, \"lr\": 0.01},\n",
    "    {\"n_h\": 8, \"lr\": 0.01},\n",
    "    {\"n_h\": 16, \"lr\": 0.005}\n",
    "]\n",
    "\n",
    "for cfg in configs:\n",
    "    print(\"\\n==============================\")\n",
    "    print(\"Configuración:\", cfg)\n",
    "    print(\"==============================\")\n",
    "\n",
    "    W1, b1, W2, b2 = train_nn(\n",
    "        X_train, y_train,\n",
    "        n_h=cfg[\"n_h\"],\n",
    "        learning_rate=cfg[\"lr\"],\n",
    "        num_iterations=3000\n",
    "    )\n",
    "\n",
    "    y_pred_train = predict(X_train, W1, b1, W2, b2)\n",
    "    y_pred_test = predict(X_test, W1, b1, W2, b2)\n",
    "\n",
    "    train_acc = accuracy_score(y_train.ravel(), y_pred_train.ravel())\n",
    "    test_acc = accuracy_score(y_test.ravel(), y_pred_test.ravel())\n",
    "\n",
    "    print(f\"Accuracy train: {train_acc:.3f}\")\n",
    "    print(f\"Accuracy test : {test_acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2679d346",
   "metadata": {},
   "source": [
    "### **Interpretación de los resultados experimentales**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644fef5f",
   "metadata": {},
   "source": [
    "#### Configuración 1: **n_h = 4, learning_rate = 0.01**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d701124e",
   "metadata": {},
   "source": [
    "- El costo disminuye lentamente a lo largo de las iteraciones.\n",
    "\n",
    "- La reducción del costo es limitada, lo que indica una capacidad de aprendizaje restringida.\n",
    "\n",
    "El modelo alcanza:\n",
    "\n",
    "- **Accuracy entrenamiento:** 77.8%\n",
    "\n",
    "- **Accuracy prueba:** 79.9%\n",
    "\n",
    "Esta configuración presenta subajuste (underfitting), ya que la red es demasiado simple para capturar patrones complejos del dataset Titanic.\n",
    "\n",
    "**Interpretación basada en el dataset:**\n",
    "\n",
    "El modelo probablemente aprende reglas simples como:\n",
    "\n",
    "- “Las mujeres sobreviven más que los hombres”.\n",
    "\n",
    "- “Pasajeros de primera clase tienen mayor probabilidad de sobrevivir”.\n",
    "\n",
    "Sin embargo, no logra capturar interacciones más sutiles, por ejemplo:\n",
    "\n",
    "- Diferencias entre hombres jóvenes y adultos.\n",
    "\n",
    "- Efecto combinado de clase y tarifa.\n",
    "\n",
    "**Esta configuracion de la red presenta subajuste para el problema Titanic.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a43b1b",
   "metadata": {},
   "source": [
    "#### Configuración 2: n_h = 8, learning_rate = 0.01\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec18eb2",
   "metadata": {},
   "source": [
    "- El costo disminuye de forma más pronunciada que en la configuración anterior.\n",
    "\n",
    "- El modelo logra aprender mejor la relación entre las variables.\n",
    "\n",
    "Se obtiene:\n",
    "\n",
    "- **Accuracy entrenamiento:** 80.9%\n",
    "\n",
    "- **Accuracy prueba:** 79.3%\n",
    "\n",
    "- Existe una mejora clara respecto a n_h = 4.\n",
    "\n",
    "La diferencia pequeña entre entrenamiento y prueba indica buena generalización, aunque aún con margen de mejora.\n",
    "\n",
    "**Interpretación en Titanic:**\n",
    "\n",
    "La red ahora puede modelar relaciones como:\n",
    "\n",
    "- Mujeres en tercera clase sobreviven más que hombres en primera.\n",
    "\n",
    "- Pasajeros jóvenes con familiares a bordo tienen mayor probabilidad de supervivencia.\n",
    "\n",
    "- Captura mejor la interacción entre variables demográficas y socioeconómicas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2b1970",
   "metadata": {},
   "source": [
    "#### Configuración 3: n_h = 16, learning_rate = 0.005\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e065e3ed",
   "metadata": {},
   "source": [
    "- El costo presenta una disminución menos estable.\n",
    "\n",
    "- El modelo no logra converger correctamente.\n",
    "\n",
    "Los resultados son:\n",
    "\n",
    "- **Accuracy entrenamiento:** 68.1%\n",
    "\n",
    "- **Accuracy prueba:** 65.4%\n",
    "\n",
    "Esta configuración muestra mal ajuste de hiperparámetros, donde una tasa de aprendizaje inadecuada impide un entrenamiento eficiente.\n",
    "\n",
    "Interpretación en Titanic:\n",
    "\n",
    "- La red tiene suficiente capacidad teórica, pero:\n",
    "\n",
    "- Aprende muy lentamente.\n",
    "\n",
    "- No logra identificar relaciones claras entre variables.\n",
    "\n",
    "El modelo queda “atrapado” cerca de una solución pobre."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959fe80d",
   "metadata": {},
   "source": [
    "### Comparación general de configuraciones\n",
    "\n",
    "- Aumentar el número de neuronas mejora la capacidad del modelo hasta cierto punto.\n",
    "\n",
    "- Una red demasiado pequeña produce subajuste.\n",
    "\n",
    "- Un mal ajuste del learning rate puede provocar mala convergencia, incluso con una red más grande.\n",
    "\n",
    "- La configuración con n_h = 8 y learning_rate = 0.01 ofrece el mejor equilibrio entre complejidad y generalización.\n",
    "\n",
    "Estos resultados demuestran que el desempeño de una red neuronal depende fuertemente del ajuste de sus hiperparámetros. No siempre una red más grande garantiza mejores resultados, y una tasa de aprendizaje inapropiada puede deteriorar significativamente el rendimiento del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373673a8",
   "metadata": {},
   "source": [
    "## Comparación con Keras / TensorFlow (Titanic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1489bfb3",
   "metadata": {},
   "source": [
    "Para comparar el desempeño de la red neuronal implementada desde cero, se construira un modelo equivalente utilizando Keras (TensorFlow). Dado que Keras espera los datos con la forma (muestras, características), fue necesario reorganizar las matrices utilizadas en la implementación manual, que estaban en formato (características, muestras). Por esta razón, se transpuso X_train y X_test y se ajustó la forma de y_train y y_test para que fueran compatibles con el entrenamiento y evaluación en Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e1f0330",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3c53227",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_keras = X_train.T\n",
    "X_test_keras = X_test.T\n",
    "y_train_keras = y_train.T\n",
    "y_test_keras = y_test.T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb190ad",
   "metadata": {},
   "source": [
    "**Definición del modelo en Keras**\n",
    "- Se definió un modelo Sequential con Keras.\n",
    "\n",
    "- Se utilizó una capa oculta con activación ReLU.\n",
    "\n",
    "- La capa de salida usa activación sigmoide para clasificación binaria.\n",
    "\n",
    "- Se empleó el optimizador Adam y la función de pérdida binary crossentropy.\n",
    "\n",
    "- El número de neuronas y la tasa de aprendizaje se dejan como parámetros configurables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3815c7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_keras_model(input_dim, hidden_units=16, learning_rate=0.001):\n",
    "    model = Sequential([\n",
    "        Dense(hidden_units, activation=\"relu\", input_shape=(input_dim,)),\n",
    "        Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1231f815",
   "metadata": {},
   "source": [
    "**Entrenamiento del modelo en Keras**\n",
    "\n",
    "- Se creó el modelo con la arquitectura definida previamente.\n",
    "\n",
    "- El entrenamiento se realizó durante 50 épocas.\n",
    "\n",
    "- Se utilizó un tamaño de lote (batch size) de 32.\n",
    "\n",
    "- Se empleó el conjunto de prueba como datos de validación.\n",
    "\n",
    "- Durante el entrenamiento se monitorearon la pérdida y el accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8986018",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Angela\\anaconda3\\envs\\tfia\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.4340 - loss: 0.7836 - val_accuracy: 0.4749 - val_loss: 0.6845\n",
      "Epoch 2/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4663 - loss: 0.7355 - val_accuracy: 0.5140 - val_loss: 0.6537\n",
      "Epoch 3/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5702 - loss: 0.6945 - val_accuracy: 0.7318 - val_loss: 0.6276\n",
      "Epoch 4/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6924 - loss: 0.6602 - val_accuracy: 0.7430 - val_loss: 0.6049\n",
      "Epoch 5/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7093 - loss: 0.6312 - val_accuracy: 0.7486 - val_loss: 0.5850\n",
      "Epoch 6/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7374 - loss: 0.6047 - val_accuracy: 0.7709 - val_loss: 0.5665\n",
      "Epoch 7/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7556 - loss: 0.5818 - val_accuracy: 0.7709 - val_loss: 0.5499\n",
      "Epoch 8/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7556 - loss: 0.5608 - val_accuracy: 0.7654 - val_loss: 0.5347\n",
      "Epoch 9/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7697 - loss: 0.5424 - val_accuracy: 0.7877 - val_loss: 0.5209\n",
      "Epoch 10/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7753 - loss: 0.5270 - val_accuracy: 0.7821 - val_loss: 0.5078\n",
      "Epoch 11/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7767 - loss: 0.5130 - val_accuracy: 0.7765 - val_loss: 0.4966\n",
      "Epoch 12/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7837 - loss: 0.5003 - val_accuracy: 0.7765 - val_loss: 0.4860\n",
      "Epoch 13/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7893 - loss: 0.4890 - val_accuracy: 0.7877 - val_loss: 0.4755\n",
      "Epoch 14/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7963 - loss: 0.4786 - val_accuracy: 0.7877 - val_loss: 0.4670\n",
      "Epoch 15/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7963 - loss: 0.4701 - val_accuracy: 0.7877 - val_loss: 0.4591\n",
      "Epoch 16/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8006 - loss: 0.4628 - val_accuracy: 0.7877 - val_loss: 0.4532\n",
      "Epoch 17/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8020 - loss: 0.4566 - val_accuracy: 0.7933 - val_loss: 0.4474\n",
      "Epoch 18/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8048 - loss: 0.4512 - val_accuracy: 0.7933 - val_loss: 0.4427\n",
      "Epoch 19/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8076 - loss: 0.4464 - val_accuracy: 0.7933 - val_loss: 0.4392\n",
      "Epoch 20/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8090 - loss: 0.4425 - val_accuracy: 0.7933 - val_loss: 0.4357\n",
      "Epoch 21/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8076 - loss: 0.4394 - val_accuracy: 0.7933 - val_loss: 0.4328\n",
      "Epoch 22/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8076 - loss: 0.4368 - val_accuracy: 0.7933 - val_loss: 0.4310\n",
      "Epoch 23/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8104 - loss: 0.4342 - val_accuracy: 0.7933 - val_loss: 0.4285\n",
      "Epoch 24/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8104 - loss: 0.4320 - val_accuracy: 0.7933 - val_loss: 0.4264\n",
      "Epoch 25/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8118 - loss: 0.4304 - val_accuracy: 0.7933 - val_loss: 0.4253\n",
      "Epoch 26/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8118 - loss: 0.4285 - val_accuracy: 0.7933 - val_loss: 0.4233\n",
      "Epoch 27/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8146 - loss: 0.4270 - val_accuracy: 0.7933 - val_loss: 0.4225\n",
      "Epoch 28/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8146 - loss: 0.4258 - val_accuracy: 0.7933 - val_loss: 0.4213\n",
      "Epoch 29/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8146 - loss: 0.4246 - val_accuracy: 0.7933 - val_loss: 0.4210\n",
      "Epoch 30/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8160 - loss: 0.4235 - val_accuracy: 0.7933 - val_loss: 0.4202\n",
      "Epoch 31/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8132 - loss: 0.4226 - val_accuracy: 0.7989 - val_loss: 0.4194\n",
      "Epoch 32/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8160 - loss: 0.4215 - val_accuracy: 0.7989 - val_loss: 0.4190\n",
      "Epoch 33/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8174 - loss: 0.4211 - val_accuracy: 0.7989 - val_loss: 0.4185\n",
      "Epoch 34/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8160 - loss: 0.4199 - val_accuracy: 0.7989 - val_loss: 0.4184\n",
      "Epoch 35/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8160 - loss: 0.4189 - val_accuracy: 0.7989 - val_loss: 0.4183\n",
      "Epoch 36/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8132 - loss: 0.4184 - val_accuracy: 0.7989 - val_loss: 0.4176\n",
      "Epoch 37/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8132 - loss: 0.4176 - val_accuracy: 0.7989 - val_loss: 0.4176\n",
      "Epoch 38/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8132 - loss: 0.4167 - val_accuracy: 0.7989 - val_loss: 0.4170\n",
      "Epoch 39/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8160 - loss: 0.4161 - val_accuracy: 0.7989 - val_loss: 0.4170\n",
      "Epoch 40/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8202 - loss: 0.4155 - val_accuracy: 0.7989 - val_loss: 0.4165\n",
      "Epoch 41/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8244 - loss: 0.4150 - val_accuracy: 0.8045 - val_loss: 0.4162\n",
      "Epoch 42/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8244 - loss: 0.4143 - val_accuracy: 0.8045 - val_loss: 0.4155\n",
      "Epoch 43/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8216 - loss: 0.4138 - val_accuracy: 0.8045 - val_loss: 0.4165\n",
      "Epoch 44/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8230 - loss: 0.4131 - val_accuracy: 0.8045 - val_loss: 0.4163\n",
      "Epoch 45/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8258 - loss: 0.4127 - val_accuracy: 0.8045 - val_loss: 0.4165\n",
      "Epoch 46/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8244 - loss: 0.4118 - val_accuracy: 0.8045 - val_loss: 0.4164\n",
      "Epoch 47/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8258 - loss: 0.4117 - val_accuracy: 0.8045 - val_loss: 0.4165\n",
      "Epoch 48/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8244 - loss: 0.4112 - val_accuracy: 0.8045 - val_loss: 0.4169\n",
      "Epoch 49/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8244 - loss: 0.4107 - val_accuracy: 0.8045 - val_loss: 0.4170\n",
      "Epoch 50/50\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8287 - loss: 0.4102 - val_accuracy: 0.8045 - val_loss: 0.4169\n"
     ]
    }
   ],
   "source": [
    "keras_model = build_keras_model(\n",
    "    input_dim=X_train_keras.shape[1],\n",
    "    hidden_units=16,\n",
    "    learning_rate=0.001\n",
    ")\n",
    "\n",
    "history = keras_model.fit(\n",
    "    X_train_keras,\n",
    "    y_train_keras,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test_keras, y_test_keras),\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9636196b",
   "metadata": {},
   "source": [
    "**Interpretación del entrenamiento con Keras (Titanic)**\n",
    "\n",
    "- En las primeras épocas, el modelo presenta un accuracy bajo, cercano al azar, lo cual es esperado debido a la inicialización aleatoria de los pesos.\n",
    "\n",
    "- A partir de las primeras iteraciones, tanto el accuracy de entrenamiento como el accuracy de validación aumentan progresivamente, indicando que el modelo está aprendiendo patrones relevantes del dataset Titanic.\n",
    "\n",
    "- El accuracy de validación alcanza aproximadamente 80%, valor consistente con modelos clásicos aplicados a este dataset.\n",
    "\n",
    "- La diferencia reducida entre el accuracy de entrenamiento y validación indica buena capacidad de generalización y ausencia de sobreajuste.\n",
    "\n",
    "- La disminución estable de la función de pérdida sugiere un entrenamiento correcto y una tasa de aprendizaje adecuada."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2ef027",
   "metadata": {},
   "source": [
    "**Interpretación en el contexto del Titanic**\n",
    "\n",
    "- El modelo logra identificar relaciones importantes entre variables como el sexo, la clase del pasajero y la edad.\n",
    "\n",
    "- La complejidad moderada del modelo es suficiente para capturar los patrones principales sin sobreajustar los datos.\n",
    "\n",
    "- El desempeño obtenido refleja la naturaleza ruidosa del dataset, donde no todas las variables determinan de forma clara la supervivencia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077a0714",
   "metadata": {},
   "source": [
    "**Evaluación del modelo Keras**\n",
    "\n",
    "- El modelo entrenado se evaluó utilizando el conjunto de prueba.\n",
    "\n",
    "- Se calculó la función de pérdida (loss) para medir el error del modelo.\n",
    "\n",
    "- Se obtuvo el accuracy como métrica principal de desempeño.\n",
    "\n",
    "- Los resultados reflejan el rendimiento final del modelo sobre datos no vistos durante el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d3e813f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss (Keras): 0.4169\n",
      "Test accuracy (Keras): 0.8045\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = keras_model.evaluate(X_test_keras, y_test_keras, verbose=0)\n",
    "\n",
    "print(f\"Test loss (Keras): {loss:.4f}\")\n",
    "print(f\"Test accuracy (Keras): {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e787483e",
   "metadata": {},
   "source": [
    "- El modelo alcanza un accuracy del 80.45%, clasificando correctamente a la mayoría de los pasajeros.\n",
    "\n",
    "- El desempeño refleja la capacidad del modelo para identificar patrones clave del Titanic.\n",
    "\n",
    "- Variables como el sexo, la clase del pasajero y la edad influyen significativamente en la predicción.\n",
    "\n",
    "- El valor de pérdida indica un error esperable en un dataset real y ruidoso.\n",
    "\n",
    "- El resultado es consistente con modelos típicos aplicados al problema de supervivencia del Titanic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfd4c7d",
   "metadata": {},
   "source": [
    "## Conclusiones y comparaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1415d8e",
   "metadata": {},
   "source": [
    "- La red neuronal implementada desde cero alcanzó un accuracy cercano al 80% en el dataset Titanic, demostrando que el algoritmo fue correctamente implementado.\n",
    "\n",
    "- El modelo desarrollado con Keras / TensorFlow obtuvo un mejor desempeño, alcanzando un accuracy de 80.45% en el conjunto de prueba.\n",
    "\n",
    "- La diferencia de rendimiento se debe a que Keras utiliza optimizadores más avanzados y una gestión más eficiente del entrenamiento.\n",
    "\n",
    "- A pesar de ello, los resultados de ambos modelos son comparables, lo que valida la implementación manual.\n",
    "\n",
    "- El modelo con Keras resulta más eficiente y estable para aplicaciones prácticas, mientras que el modelo manual es más útil para fines educativos y comprensión del algoritmo.\n",
    "\n",
    "- En el contexto del dataset Titanic, ninguno de los modelos alcanza una precisión perfecta debido a la complejidad y el ruido inherente a los datos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
